{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-04T18:07:35.791505Z","iopub.execute_input":"2022-08-04T18:07:35.792179Z","iopub.status.idle":"2022-08-04T18:07:35.805180Z","shell.execute_reply.started":"2022-08-04T18:07:35.792140Z","shell.execute_reply":"2022-08-04T18:07:35.804005Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data_set = pd.read_csv('/kaggle/input/human-date-to-machine-date/data_set.csv')\ndata_set[:10]","metadata":{"execution":{"iopub.status.busy":"2022-08-04T18:07:37.124118Z","iopub.execute_input":"2022-08-04T18:07:37.124824Z","iopub.status.idle":"2022-08-04T18:07:37.162113Z","shell.execute_reply.started":"2022-08-04T18:07:37.124784Z","shell.execute_reply":"2022-08-04T18:07:37.161102Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-08-04T18:07:37.163992Z","iopub.execute_input":"2022-08-04T18:07:37.164415Z","iopub.status.idle":"2022-08-04T18:07:41.621399Z","shell.execute_reply.started":"2022-08-04T18:07:37.164378Z","shell.execute_reply":"2022-08-04T18:07:41.620477Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2022-08-04T18:07:41.624372Z","iopub.execute_input":"2022-08-04T18:07:41.625473Z","iopub.status.idle":"2022-08-04T18:07:41.631971Z","shell.execute_reply.started":"2022-08-04T18:07:41.625406Z","shell.execute_reply":"2022-08-04T18:07:41.630959Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.Sequential()","metadata":{"execution":{"iopub.status.busy":"2022-08-04T18:07:41.635171Z","iopub.execute_input":"2022-08-04T18:07:41.635522Z","iopub.status.idle":"2022-08-04T18:07:45.408238Z","shell.execute_reply.started":"2022-08-04T18:07:41.635490Z","shell.execute_reply":"2022-08-04T18:07:45.407296Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"set(\"dfdfsd \")","metadata":{"execution":{"iopub.status.busy":"2022-08-04T18:07:45.410523Z","iopub.execute_input":"2022-08-04T18:07:45.411398Z","iopub.status.idle":"2022-08-04T18:07:45.421027Z","shell.execute_reply.started":"2022-08-04T18:07:45.411359Z","shell.execute_reply":"2022-08-04T18:07:45.419253Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# creating vocabulary \n#human and machine\nhuman_vocab = set()\nmachine_vocab = set()\nfor row in data_set.index:\n    h, m = data_set.humanized[row].lower(), data_set.machine[row]\n    human_vocab.update(tuple(h))\n    machine_vocab.update(tuple(m))\nhuman_vocab = dict(zip(sorted(human_vocab) + ['<unk>', '<pad>'], list(range(len(human_vocab) + 2))))\nmachine_vocab = dict(zip(sorted(machine_vocab), list(range(len(machine_vocab)))))\nmachine_vocab, len(machine_vocab), len(human_vocab)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T18:07:45.425528Z","iopub.execute_input":"2022-08-04T18:07:45.425818Z","iopub.status.idle":"2022-08-04T18:07:45.632309Z","shell.execute_reply.started":"2022-08-04T18:07:45.425793Z","shell.execute_reply":"2022-08-04T18:07:45.631318Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# process data\n# input pd [humanized, machine]\n# output \n# X [list of list of words] \n# Y [list of list of words] \n# Xoh [list of list of dict of words] \n# Yoh [list of list of dict of works]\n\n# Tx data_set.humanized.map(len).max() -> 27, lets take 30\n# Ty data_set.machine.map(len).max() -> 10\n\nX = []\nY = []\nTx = 30\nTy = 10\nm = len(data_set)\n\ndef string_to_int(text, vocab, T=30):\n    text = text.lower()\n    if len(text) > T:\n        text = text[:T]\n    ints = [vocab.get(text[i]) if len(text) > i else vocab.get('<pad>') for i in range(T)]\n    return ints\n\nfor i in data_set.index:\n    hd, md = data_set.humanized[i], data_set.machine[i]\n    X.append(string_to_int(hd, human_vocab, Tx))\n    Y.append(string_to_int(md, machine_vocab, Ty))\nX = np.array(X)\nY = np.array(Y)\nXoh = np.array(list(map(lambda x: tf.keras.utils.to_categorical(x, num_classes=len(human_vocab)), X)))\nYoh = np.array(list(map(lambda x: tf.keras.utils.to_categorical(x, num_classes=len(machine_vocab)), Y)))\nX.shape, Y.shape, Xoh.shape, Yoh.shape, m","metadata":{"execution":{"iopub.status.busy":"2022-08-04T18:07:45.633606Z","iopub.execute_input":"2022-08-04T18:07:45.634032Z","iopub.status.idle":"2022-08-04T18:07:46.297409Z","shell.execute_reply.started":"2022-08-04T18:07:45.633997Z","shell.execute_reply":"2022-08-04T18:07:46.296363Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# one step attention\n# input -> a [all activations of Bi LSTM] shape (30, 37)\n# input -> s [t-1 hidden state of post attention LSTM] shape ()\n\ndef one_step_attention(a, s_prev, dense_1, dense_2):\n    s_prev = tf.keras.layers.RepeatVector(Tx)(s_prev)\n    con = tf.keras.layers.Concatenate(axis=-1)([a, s_prev])\n    print('con', con.shape)\n    dense1 = dense_1(con)\n    dense2 = dense_2(dense1)\n    energies = tf.keras.activations.softmax(dense2)\n    context = tf.keras.layers.Dot(axes=1)([energies, a])\n    return context\n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-04T18:07:46.298788Z","iopub.execute_input":"2022-08-04T18:07:46.299242Z","iopub.status.idle":"2022-08-04T18:07:46.306668Z","shell.execute_reply.started":"2022-08-04T18:07:46.299206Z","shell.execute_reply":"2022-08-04T18:07:46.305543Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n    X = tf.keras.Input(shape=(Tx, human_vocab_size))\n    s0 = tf.keras.Input(shape=(n_s,))\n    c0 = tf.keras.Input(shape=(n_s,))\n    s = s0\n    c = c0\n    \n    outputs = []\n    bilstm = tf.keras.layers.LSTM(n_a, return_sequences=True)\n    a = tf.keras.layers.Bidirectional(bilstm)(X)\n    print(a.shape)\n    post_lstm = tf.keras.layers.LSTM(n_s, return_state=True)\n    dense_1 = tf.keras.layers.Dense(10, activation='relu')\n    dense_2 = tf.keras.layers.Dense(1, activation='relu')\n    dense_out = tf.keras.layers.Dense(machine_vocab_size, activation='softmax')\n    for t in range(Ty):\n        context = one_step_attention(a, s, dense_1, dense_2)\n        print(context.shape, 'context')\n        s, _, c = post_lstm(context, initial_state=[s, c])\n        out = dense_out(s)\n        outputs.append(out)\n    print(outputs[0].shape, Ty)\n    return tf.keras.models.Model(inputs=[X, s0, c0], outputs=outputs)\n\nsample_model = model(Tx, Ty, 32, 64, len(human_vocab), len(machine_vocab))\nsample_model.summary()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-04T18:07:46.309639Z","iopub.execute_input":"2022-08-04T18:07:46.310750Z","iopub.status.idle":"2022-08-04T18:07:49.098993Z","shell.execute_reply.started":"2022-08-04T18:07:46.310712Z","shell.execute_reply":"2022-08-04T18:07:49.097993Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"sample_model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999,decay=0.01), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-08-04T11:07:49.162936Z","iopub.execute_input":"2022-08-04T11:07:49.163393Z","iopub.status.idle":"2022-08-04T11:07:49.175907Z","shell.execute_reply.started":"2022-08-04T11:07:49.163350Z","shell.execute_reply":"2022-08-04T11:07:49.175040Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"s0 = np.zeros((m, 64))\nc0 = np.zeros((m, 64))\noutputs = list(Yoh.swapaxes(0, 1))\nprint(outputs[0].shape)\nsample_model.fit(x=[Xoh, s0, c0], y=outputs, batch_size=100, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T11:07:49.790801Z","iopub.execute_input":"2022-08-04T11:07:49.791186Z","iopub.status.idle":"2022-08-04T11:08:58.682148Z","shell.execute_reply.started":"2022-08-04T11:07:49.791155Z","shell.execute_reply":"2022-08-04T11:08:58.681225Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\nmachine_vocab_reversed = dict((v, k) for k, v in machine_vocab.items())\nfor example in EXAMPLES:\n    numerized = string_to_int(example, human_vocab)\n    one_hot = np.array([list(map(lambda x: tf.keras.utils.to_categorical(x, num_classes=len(human_vocab)), numerized))])\n    prediction = sample_model.predict_step([one_hot, s0[:1, :], c0[:1, :]])\n    pred_numerized = [np.argmax(x) for x in prediction]\n    pred_alpha = [machine_vocab_reversed[x] for x in pred_numerized]\n    print(''.join(pred_alpha))","metadata":{"execution":{"iopub.status.busy":"2022-08-04T10:49:52.884539Z","iopub.execute_input":"2022-08-04T10:49:52.885008Z","iopub.status.idle":"2022-08-04T10:49:53.404246Z","shell.execute_reply.started":"2022-08-04T10:49:52.884969Z","shell.execute_reply":"2022-08-04T10:49:53.403071Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-07-28T11:45:47.487833Z","iopub.execute_input":"2022-07-28T11:45:47.488372Z","iopub.status.idle":"2022-07-28T11:45:47.497175Z","shell.execute_reply.started":"2022-07-28T11:45:47.488331Z","shell.execute_reply":"2022-07-28T11:45:47.495856Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}